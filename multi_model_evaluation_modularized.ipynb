{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump\n",
    "\n",
    "def load_and_preprocess_data(filename):\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - features: Processed feature data.\n",
    "    - labels: Corresponding labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(filename).dropna()\n",
    "    drop_cols = ['ST', 'Town', 'county', 'Bank_Name', 'State_Town', 'State_County'] + \\\n",
    "                ['ST' + state for state in ['AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'IA', 'ID', 'IL', \n",
    "                                          'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', \n",
    "                                          'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', \n",
    "                                          'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']]\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    df['unique'] = df.pop('unique')\n",
    "    return df.drop('ReopenedByMarch29_UR', axis=1), df['ReopenedByMarch29_UR']\n",
    "\n",
    "def optimize_parameters(model, param_grid, features, labels):\n",
    "    \"\"\"\n",
    "    Optimize model parameters using GridSearchCV.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model instance.\n",
    "    - param_grid: Grid of hyperparameters for the model.\n",
    "    - features: The feature data.\n",
    "    - labels: The label data.\n",
    "\n",
    "    Returns:\n",
    "    - best_params_: The best parameters from the grid search.\n",
    "    \"\"\"\n",
    "    features_opt = features.drop(['unique'], axis=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(features_opt, labels)\n",
    "    return grid_search.best_params_\n",
    "\n",
    "def run_model(model, best_params, num_iterations, features, labels, model_name):\n",
    "    \"\"\"\n",
    "    Run a given model multiple times and store the results.\n",
    "    \n",
    "    Args:\n",
    "        model (function): The model class to instantiate and run.\n",
    "        best_params (dict): Optimal parameters for the model.\n",
    "        num_iterations (int): Number of iterations to run the model.\n",
    "        features (DataFrame): Feature matrix.\n",
    "        labels (Series): Target labels.\n",
    "        model_name (str): Name of the model for labeling purposes.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame, list: Combined results over iterations and accuracies for each iteration.\n",
    "    \"\"\"\n",
    "    combined_results = pd.DataFrame()\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "        # Extract 'unique' column and then drop it because it is in a string format\n",
    "        X_test_unique = X_test['unique']\n",
    "        X_train = X_train.drop(['unique'], axis=1)\n",
    "        X_test = X_test.drop(['unique'], axis=1)\n",
    "\n",
    "        model_instance = model(**best_params)\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        predictions = model_instance.predict(X_test)\n",
    "\n",
    "        # Construct the result dataframe for this iteration\n",
    "        result_df = pd.DataFrame({\n",
    "            'unique': X_test_unique,\n",
    "            f'prediction{model_name}{i}': predictions\n",
    "        })\n",
    "\n",
    "        if i == 0:\n",
    "            combined_results = result_df\n",
    "        else:\n",
    "            combined_results = pd.merge(result_df, combined_results, on=\"unique\", how=\"outer\")\n",
    "\n",
    "        accuracies.append(accuracy_score(y_test, predictions))\n",
    "\n",
    "    combined_results = combined_results.fillna(8).groupby('unique').sum()\n",
    "    prediction_columns = [f'prediction{model_name}{i}' for i in range(num_iterations)]\n",
    "    combined_results = combined_results[combined_results[prediction_columns].lt(9).all(axis=1)]\n",
    "\n",
    "    return combined_results, accuracies\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    The main execution function of the script.\n",
    "    \n",
    "    Steps performed by the function:\n",
    "    1. Load and preprocess the dataset from the provided Excel file.\n",
    "    2. Define hyperparameter configurations for various models.\n",
    "    3. For each model:\n",
    "       a. Determine the best hyperparameters using grid search and cross-validation.\n",
    "       b. Train the model multiple times (20 iterations) using the optimal parameters.\n",
    "       c. Save the aggregated results to a CSV file.\n",
    "       d. Print the average accuracy achieved across all iterations.\n",
    "\n",
    "    Models used and optimized:\n",
    "    - RandomForestClassifier\n",
    "    - Support Vector Classifier\n",
    "    - KNeighborsClassifier\n",
    "    - LogisticRegression\n",
    "\n",
    "    Outputs:\n",
    "    - For each model, a CSV file with aggregated results across all iterations.\n",
    "    - Printed average accuracy for each model.\n",
    "\n",
    "    \"\"\"\n",
    "    # Data Loading\n",
    "    features, labels = load_and_preprocess_data('ConcurrentExecution/RAdatafile_filtered.xlsx')\n",
    "\n",
    "    # Model configuration: a tuple of (Model Class, Parameter Grid, Model Name)\n",
    "    models_config = [\n",
    "    (RandomForestClassifier, {\n",
    "        # Maximum depth of the tree. Helps in controlling over-fitting. None means nodes are expanded until all leaves are pure.\n",
    "        'max_depth': [2, 4, 6, 8, 10, 12, 14, 16], \n",
    "        # Number of trees in the forest.\n",
    "        'n_estimators': [50, 100, 150, 200], \n",
    "        # Fraction of samples used for fitting the individual base learners.\n",
    "        'max_samples': [0.3, 0.4, 0.5] \n",
    "    }, \"RF\"),\n",
    "\n",
    "    (SVC, {\n",
    "        # Regularization parameter. Smaller values specify stronger regularization.\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        # Kernel coefficient. 'scale' means it's calculated from the data.\n",
    "        'gamma': [1, 0.1, 0.01, 0.001], \n",
    "        # Specifies the kernel type to be used in the algorithm.\n",
    "        'kernel': ['linear', 'rbf'] \n",
    "    }, \"SVM\"),\n",
    "\n",
    "    (KNeighborsClassifier, {\n",
    "        # Number of neighbors to use for kneighbors queries.\n",
    "        'n_neighbors': list(range(1, 31)), \n",
    "        # Weight function used in prediction. Uniform means all points are weighted equally.\n",
    "        'weights': ['uniform', 'distance'], \n",
    "        # The distance metric to use for the tree.\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski'] \n",
    "    }, \"KNN\"),\n",
    "\n",
    "    (LogisticRegression, {\n",
    "        # Inverse of regularization strength. Smaller values cause stronger regularization.\n",
    "        'C': np.logspace(-3, 3, 7), \n",
    "        # Used to specify the norm used in the penalization.\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'], \n",
    "        # Algorithm to use in the optimization problem.\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }, \"LR\")\n",
    "]\n",
    "    # Iterate over models to optimize, run and save results\n",
    "    for model, param_grid, model_name in models_config:\n",
    "        best_params = optimize_parameters(model(), param_grid, features, labels)\n",
    "        results, accuracies = run_model(model, best_params, 20, features, labels, model_name)\n",
    "        results.to_csv(f'{model_name}Results.csv')\n",
    "        print(f\"{model_name} Accuracy: {np.mean(accuracies):.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
